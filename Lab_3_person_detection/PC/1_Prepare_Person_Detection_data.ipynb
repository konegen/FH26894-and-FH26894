{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/\"\n",
    "data_coco = \"data/coco/\"\n",
    "# Number of training images to pick from each category\n",
    "num_images = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For person detection, the [COCO data set](https://cocodataset.org) is used. In the first step, the image data and the label information are downloaded. <br>\n",
    "The data then gets extracted to the `\"data/coco\"` folder and the zip files will be deleted.<br>\n",
    "It should be noted that the COCO training dataset is over 18GB (~120,000 images). Therefore, the download can take a longer time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(data_path):\n",
    "    os.mkdir(data_path)\n",
    "if not os.path.isdir(data_coco):\n",
    "    os.mkdir(data_coco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(data_coco + \"train2017\"):\n",
    "    url = \"http://images.cocodataset.org/zips/train2017.zip\"\n",
    "    wget.download(url, data_coco)\n",
    "\n",
    "    with zipfile.ZipFile(data_coco + \"train2017.zip\",\"r\") as zip_ref:\n",
    "        zip_ref.extractall(data_coco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(data_coco + \"annotations\"):\n",
    "    url = \"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\"\n",
    "    wget.download(url, data_coco)\n",
    "\n",
    "    with zipfile.ZipFile(data_coco + \"annotations_trainval2017.zip\",\"r\") as zip_ref:\n",
    "        zip_ref.extractall(data_coco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(data_coco + \"train2017.zip\"):\n",
    "    os.remove(data_coco + \"train2017.zip\")\n",
    "if os.path.isfile(data_coco + \"annotations_trainval2017.zip\"):\n",
    "    os.remove(data_coco + \"annotations_trainval2017.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the data describing the images from the file you downloaded before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = json.load(open(data_coco + \"annotations/instances_train2017.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just the annotations are important. This data is saved in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segmentation</th>\n",
       "      <th>area</th>\n",
       "      <th>iscrowd</th>\n",
       "      <th>image_id</th>\n",
       "      <th>bbox</th>\n",
       "      <th>category_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[239.97, 260.24, 222.04, 270.49, 199.84, 253....</td>\n",
       "      <td>2765.14865</td>\n",
       "      <td>0</td>\n",
       "      <td>558840</td>\n",
       "      <td>[199.84, 200.46, 77.71, 70.88]</td>\n",
       "      <td>58</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[247.71, 354.7, 253.49, 346.99, 276.63, 337.3...</td>\n",
       "      <td>1545.42130</td>\n",
       "      <td>0</td>\n",
       "      <td>200365</td>\n",
       "      <td>[234.22, 317.11, 149.39, 38.55]</td>\n",
       "      <td>58</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[274.58, 405.68, 298.32, 405.68, 302.45, 402....</td>\n",
       "      <td>5607.66135</td>\n",
       "      <td>0</td>\n",
       "      <td>200365</td>\n",
       "      <td>[239.48, 347.87, 160.0, 57.81]</td>\n",
       "      <td>58</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[296.65, 388.33, 296.65, 388.33, 297.68, 388....</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>200365</td>\n",
       "      <td>[296.65, 388.33, 1.03, 0.0]</td>\n",
       "      <td>58</td>\n",
       "      <td>918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[251.87, 356.13, 260.13, 343.74, 300.39, 335....</td>\n",
       "      <td>800.41325</td>\n",
       "      <td>0</td>\n",
       "      <td>200365</td>\n",
       "      <td>[251.87, 333.42, 125.94, 22.71]</td>\n",
       "      <td>58</td>\n",
       "      <td>1072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        segmentation        area  iscrowd  \\\n",
       "0  [[239.97, 260.24, 222.04, 270.49, 199.84, 253....  2765.14865        0   \n",
       "1  [[247.71, 354.7, 253.49, 346.99, 276.63, 337.3...  1545.42130        0   \n",
       "2  [[274.58, 405.68, 298.32, 405.68, 302.45, 402....  5607.66135        0   \n",
       "3  [[296.65, 388.33, 296.65, 388.33, 297.68, 388....     0.00000        0   \n",
       "4  [[251.87, 356.13, 260.13, 343.74, 300.39, 335....   800.41325        0   \n",
       "\n",
       "   image_id                             bbox  category_id    id  \n",
       "0    558840   [199.84, 200.46, 77.71, 70.88]           58   156  \n",
       "1    200365  [234.22, 317.11, 149.39, 38.55]           58   509  \n",
       "2    200365   [239.48, 347.87, 160.0, 57.81]           58   603  \n",
       "3    200365      [296.65, 388.33, 1.03, 0.0]           58   918  \n",
       "4    200365  [251.87, 333.42, 125.94, 22.71]           58  1072  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations = pd.DataFrame(json_data[\"annotations\"])\n",
    "annotations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All unnecessary data is removed from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>558840</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200365</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200365</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200365</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200365</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id  category_id\n",
       "0    558840           58\n",
       "1    200365           58\n",
       "2    200365           58\n",
       "3    200365           58\n",
       "4    200365           58"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations.drop(labels=[\"segmentation\", \"area\", \"iscrowd\", \"bbox\", \"id\"], axis=1, inplace=True)\n",
    "annotations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images of the Person class are stored in a new DataFrame. Then all duplicates of an image are removed.<br>\n",
    "Additionally, we just want to take `num_images` to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_person = annotations[annotations[\"category_id\"]==1]\n",
    "df_person = df_person.drop_duplicates(subset=[\"image_id\"])\n",
    "df_person.reset_index(drop=True, inplace=True)\n",
    "df_person = df_person.loc[:num_images-1]\n",
    "df_person.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same is done for the remaining classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116912, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_person = annotations[annotations[\"category_id\"]!=1]\n",
    "df_no_person = df_no_person.drop_duplicates(subset=[\"image_id\"])\n",
    "df_no_person.reset_index(drop=True)\n",
    "df_no_person.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is checked if there are images that appear in both DataFrames.<br>\n",
    "All images that appear in both DataFrames are removed from the DataFrame that contains the images without persons.<br>\n",
    "After that the DataFrame is reduced to `num_images`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond = df_no_person[\"image_id\"].isin(df_person[\"image_id\"])\n",
    "df_no_person.drop(df_no_person[cond].index, inplace = True)\n",
    "df_no_person.reset_index(drop=True, inplace = True)\n",
    "df_no_person = df_no_person.loc[:num_images-1]\n",
    "df_no_person.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the new data set for person detection is created, the directories in which the images will be stored must be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = data_path + \"train/\"\n",
    "person_path = train_path + \"person/\"\n",
    "no_person_path = train_path + \"no_person/\"\n",
    "\n",
    "if not os.path.isdir(data_path + \"train\"):\n",
    "    os.mkdir(data_path + \"train\")\n",
    "    os.mkdir(person_path)\n",
    "    os.mkdir(no_person_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image names of all images that contain people and those that do not contain people are stored in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person images: 10000\n",
      "No person images: 10000\n"
     ]
    }
   ],
   "source": [
    "dfp = list(df_person[\"image_id\"])\n",
    "dfnp = list(df_no_person[\"image_id\"])\n",
    "print(\"Person images:\", len(dfp))\n",
    "print(\"No person images:\", len(dfnp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10,000 images (`num_images`) for each of the two classes are copied from the downloaded COCO dataset into the folders created previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_images):\n",
    "    shutil.copy(data_coco + \"train2017/\" + str(dfp[i]).zfill(12) + \".jpg\", person_path + str(dfp[i]).zfill(12) + \".jpg\")\n",
    "    shutil.copy(data_coco + \"train2017/\" + str(dfnp[i]).zfill(12) + \".jpg\", no_person_path + str(dfnp[i]).zfill(12) + \".jpg\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40f3738048d625aca6ef2045e82a11ef03f82a573df70403d898691e42b7f48e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('Person_Detection': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
